# deepfake-detection-system
Deepfake detection system using video as the primary modality with audio and spatio-temporal features for improved accuracy.

## üìÇ Datasets Used

This project was trained and evaluated using the following publicly available datasets:

- **[FakeAVCeleb](https://github.com/DASH-Lab/FakeAVCeleb)**  
  Multimodal deepfake dataset containing manipulated videos with both audio and visual modifications.

- **[CREMA-D](https://github.com/CheyneyComputerScience/CREMA-D)**  
  Crowd-sourced emotional multimodal actors dataset used for audio augmentation.

- **[Meta's Casual Conversations Dataset](https://ai.meta.com/datasets/casual-conversations/)**  
  Dataset containing real conversational videos, used for bias testing and evaluation.

‚ö†Ô∏è *Note:* Due to dataset licensing and size, the raw data is not included in this repository.  
To reproduce results, please download from the official sources above.

## üìú License
This project is licensed under the 
[Creative Commons Attribution-NonCommercial 4.0 International License (CC BY-NC 4.0)](https://creativecommons.org/licenses/by-nc/4.0/).

You are free to use, share, and adapt this work **for non-commercial purposes only**, with proper attribution.  
Commercial use is strictly prohibited.
